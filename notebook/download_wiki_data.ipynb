{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "download_language = {\"English\": \"en\",\n",
    "\"Spanish\": \"es\",\n",
    "\"French\": \"fr\",\n",
    "\"Italian\": \"it\",\n",
    "\"German\": \"de\",\n",
    "\"Portuguese\": \"pt\",\n",
    "\"Dutch\": \"nl\",\n",
    "\"Swedish\": \"sv\",\n",
    "\"Norwegian\": \"no\",\n",
    "\"Danish\": \"da\",\n",
    "\"Finnish\": \"fi\",\n",
    "\"Latin\": \"la\",\n",
    "\"Romanian\": \"ro\",\n",
    "\"Catalan\": \"ca\",\n",
    "\"Hungarian\": \"hu\",\n",
    "\"Polish\": \"pl\",\n",
    "\"Czech\": \"cs\",\n",
    "\"Slovak\": \"sk\",\n",
    "\"Slovenian\": \"sl\",\n",
    "\"Croatian\": \"hr\"}\n",
    "\n",
    "print(len(download_language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for d in datasets_list:\n",
    "#     if \"wikimedia\" in d:\n",
    "#         print(d)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"../data/huggingface_data_README.yml\", \"r\") as stream:\n",
    "    try:\n",
    "        dataset_readme = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langcodes import Language\n",
    "\n",
    "def get_language_name(iso_code):\n",
    "    try:\n",
    "        lang = Language.get(iso_code)\n",
    "        return lang.display_name().title()\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n",
      "{'Abkhazian': 'ab', 'Achinese': 'ace', 'Adyghe': 'ady', 'Afrikaans': 'af', 'Tosk Albanian': 'als', 'Southern Altai': 'alt', 'Amharic': 'am', 'Amis': 'ami', 'Aragonese': 'an', 'Old English': 'ang', 'Angika': 'anp', 'Arabic': 'ar', 'Aramaic': 'arc', 'Moroccan Arabic': 'ary', 'Egyptian Arabic': 'arz', 'Assamese': 'as', 'Asturian': 'ast', 'Atikamekw': 'atj', 'Avaric': 'av', 'Kotava': 'avk', 'Awadhi': 'awa', 'Aymara': 'ay', 'Azerbaijani': 'az', 'South Azerbaijani': 'azb', 'Bashkir': 'ba', 'Balinese': 'ban', 'Bavarian': 'bar', 'Baltic Languages': 'bat-smg', 'Central Bikol': 'bcl', 'Belarusian': 'be-x-old', 'Bulgarian': 'bg', 'Bihari Languages': 'bh', 'Bislama': 'bi', 'Banjar': 'bjn', \"Pa'O Karen\": 'blk', 'Bambara': 'bm', 'Bangla': 'bn', 'Tibetan': 'bo', 'Bishnupriya': 'bpy', 'Breton': 'br', 'Bosnian': 'bs', 'Buginese': 'bug', 'Russia Buriat': 'bxr', 'Catalan': 'ca', 'Chavacano': 'cbk-zam', 'Min Dong Chinese': 'cdo', 'Chechen': 'ce', 'Cebuano': 'ceb', 'Chamorro': 'ch', 'Cherokee': 'chr', 'Cheyenne': 'chy', 'Central Kurdish': 'ckb', 'Corsican': 'co', 'Cree': 'cr', 'Crimean Turkish': 'crh', 'Czech': 'cs', 'Kashubian': 'csb', 'Church Slavic': 'cu', 'Chuvash': 'cv', 'Welsh': 'cy', 'Danish': 'da', 'Dagbani': 'dag', 'German': 'de', 'Dinka': 'din', 'Dimli (Individual Language)': 'diq', 'Lower Sorbian': 'dsb', 'Dotyali': 'dty', 'Divehi': 'dv', 'Dzongkha': 'dz', 'Ewe': 'ee', 'Greek': 'el', 'Unknown Language [Eml]': 'eml', 'English': 'en', 'Esperanto': 'eo', 'Spanish': 'es', 'Estonian': 'et', 'Basque': 'eu', 'Extremaduran': 'ext', 'Persian': 'fa', 'Fanti': 'fat', 'Fulah': 'ff', 'Finnish': 'fi', 'Finno-Ugrian Languages': 'fiu-vro', 'Fijian': 'fj', 'Faroese': 'fo', 'Fon': 'fon', 'French': 'fr', 'Arpitan': 'frp', 'Northern Frisian': 'frr', 'Friulian': 'fur', 'Western Frisian': 'fy', 'Irish': 'ga', 'Gagauz': 'gag', 'Gan Chinese': 'gan', 'Guianese Creole French': 'gcr', 'Scottish Gaelic': 'gd', 'Galician': 'gl', 'Gilaki': 'glk', 'Guarani': 'gn', 'Goan Konkani': 'gom', 'Gorontalo': 'gor', 'Gothic': 'got', 'Ghanaian Pidgin English': 'gpe', 'Gujarati': 'gu', 'Wayuu': 'guc', 'Frafra': 'gur', 'Gun': 'guw', 'Manx': 'gv', 'Hausa': 'ha', 'Hakka Chinese': 'hak', 'Hawaiian': 'haw', 'Hebrew': 'he', 'Hindi': 'hi', 'Fiji Hindi': 'hif', 'Croatian': 'hr', 'Upper Sorbian': 'hsb', 'Haitian Creole': 'ht', 'Hungarian': 'hu', 'Armenian': 'hy', 'Western Armenian': 'hyw', 'Interlingua': 'ia', 'Indonesian': 'id', 'Interlingue': 'ie', 'Igbo': 'ig', 'Inupiaq': 'ik', 'Iloko': 'ilo', 'Ingush': 'inh', 'Ido': 'io', 'Icelandic': 'is', 'Italian': 'it', 'Inuktitut': 'iu', 'Japanese': 'ja', 'Jamaican Creole English': 'jam', 'Lojban': 'jbo', 'Javanese': 'jv', 'Georgian': 'ka', 'Kara-Kalpak': 'kaa', 'Kabyle': 'kab', 'Kabardian': 'kbd', 'Kabiyè': 'kbp', 'Tyap': 'kcg', 'Kongo': 'kg', 'Kikuyu': 'ki', 'Kazakh': 'kk', 'Kalaallisut': 'kl', 'Khmer': 'km', 'Kannada': 'kn', 'Korean': 'ko', 'Komi-Permyak': 'koi', 'Karachay-Balkar': 'krc', 'Kashmiri': 'ks', 'Colognian': 'ksh', 'Kurdish': 'ku', 'Komi': 'kv', 'Cornish': 'kw', 'Kyrgyz': 'ky', 'Latin': 'la', 'Ladino': 'lad', 'Luxembourgish': 'lb', 'Lak': 'lbe', 'Lezghian': 'lez', 'Lingua Franca Nova': 'lfn', 'Ganda': 'lg', 'Limburgish': 'li', 'Ligurian': 'lij', 'Ladin': 'lld', 'Lombard': 'lmo', 'Lingala': 'ln', 'Lao': 'lo', 'Lithuanian': 'lt', 'Latgalian': 'ltg', 'Latvian': 'lv', 'Madurese': 'mad', 'Maithili': 'mai', 'Austronesian Languages': 'map-bms', 'Moksha': 'mdf', 'Malagasy': 'mg', 'Eastern Mari': 'mhr', 'Māori': 'mi', 'Minangkabau': 'min', 'Macedonian': 'mk', 'Malayalam': 'ml', 'Mongolian': 'mn', 'Manipuri': 'mni', 'Mon': 'mnw', 'Marathi': 'mr', 'Western Mari': 'mrj', 'Malay': 'ms', 'Maltese': 'mt', 'Mirandese': 'mwl', 'Burmese': 'my', 'Erzya': 'myv', 'Mazanderani': 'mzn', 'Nahuatl Languages': 'nah', 'Neapolitan': 'nap', 'Low German': 'nds', 'Low German (Netherlands)': 'nds-nl', 'Nepali': 'ne', 'Newari': 'new', 'Nias': 'nia', 'Dutch': 'nl', 'Norwegian Nynorsk': 'nn', 'Norwegian': 'no', 'Novial': 'nov', 'N’Ko': 'nqo', 'Narom': 'nrm', 'Northern Sotho': 'nso', 'Navajo': 'nv', 'Nyanja': 'ny', 'Occitan': 'oc', 'Livvi': 'olo', 'Oromo': 'om', 'Odia': 'or', 'Ossetic': 'os', 'Punjabi': 'pa', 'Pangasinan': 'pag', 'Pampanga': 'pam', 'Papiamento': 'pap', 'Picard': 'pcd', 'Nigerian Pidgin': 'pcm', 'Pennsylvania German': 'pdc', 'Palatine German': 'pfl', 'Pali': 'pi', 'Pitcairn-Norfolk': 'pih', 'Polish': 'pl', 'Piedmontese': 'pms', 'Western Panjabi': 'pnb', 'Pontic': 'pnt', 'Pashto': 'ps', 'Portuguese': 'pt', 'Paiwan': 'pwn', 'Quechua': 'qu', 'Romansh': 'rm', 'Vlax Romani': 'rmy', 'Rundi': 'rn', 'Romanian': 'ro', 'Romance Languages': 'roa-rup', 'Romance Languages (Unknown Script [Tara])': 'roa-tara', 'Russian': 'ru', 'Rusyn': 'rue', 'Kinyarwanda': 'rw', 'Sanskrit': 'sa', 'Sakha': 'sah', 'Santali': 'sat', 'Sardinian': 'sc', 'Sicilian': 'scn', 'Scots': 'sco', 'Sindhi': 'sd', 'Northern Sami': 'se', 'Sango': 'sg', 'Serbian (Latin)': 'sh', 'Tachelhit': 'shi', 'Shan': 'shn', 'Sinhala': 'si', 'Slovak': 'sk', 'Saraiki': 'skr', 'Slovenian': 'sl', 'Samoan': 'sm', 'Inari Sami': 'smn', 'Shona': 'sn', 'Somali': 'so', 'Albanian': 'sq', 'Serbian': 'sr', 'Sranan Tongo': 'srn', 'Swati': 'ss', 'Southern Sotho': 'st', 'Saterland Frisian': 'stq', 'Sundanese': 'su', 'Swedish': 'sv', 'Swahili': 'sw', 'Silesian': 'szl', 'Sakizaya': 'szy', 'Tamil': 'ta', 'Atayal': 'tay', 'Tulu': 'tcy', 'Telugu': 'te', 'Tetum': 'tet', 'Tajik': 'tg', 'Thai': 'th', 'Tigrinya': 'ti', 'Turkmen': 'tk', 'Filipino': 'tl', 'Talysh': 'tly', 'Tswana': 'tn', 'Tongan': 'to', 'Tok Pisin': 'tpi', 'Turkish': 'tr', 'Taroko': 'trv', 'Tsonga': 'ts', 'Tatar': 'tt', 'Tumbuka': 'tum', 'Twi': 'tw', 'Tahitian': 'ty', 'Tuvinian': 'tyv', 'Udmurt': 'udm', 'Uyghur': 'ug', 'Ukrainian': 'uk', 'Urdu': 'ur', 'Uzbek': 'uz', 'Venda': 've', 'Venetian': 'vec', 'Veps': 'vep', 'Vietnamese': 'vi', 'West Flemish': 'vls', 'Volapük': 'vo', 'Walloon': 'wa', 'Waray': 'war', 'Wolof': 'wo', 'Wu Chinese': 'wuu', 'Kalmyk': 'xal', 'Xhosa': 'xh', 'Mingrelian': 'xmf', 'Yiddish': 'yi', 'Yoruba': 'yo', 'Zhuang': 'za', 'Zeelandic': 'zea', 'Chinese': 'zh', 'Min Nan Chinese': 'zh-min-nan', 'Cantonese': 'zh-yue', 'Zulu': 'zu'}\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "configs = dataset_readme['configs']\n",
    "conf_list = {}\n",
    "for conf in configs:\n",
    "    code = conf['config_name'].split('.')[-1]\n",
    "    lang = get_language_name(code)\n",
    "    if lang is not None:\n",
    "        conf_list[lang]= code \n",
    "print(len(conf_list))\n",
    "print(conf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# downloads= set(['en', 'fr'])\n",
    "downloads= set(download_language.values())\n",
    "\n",
    "configs = dataset_readme['configs']\n",
    "conf_list = []\n",
    "for conf in configs:\n",
    "    if conf['config_name'].split('.')[-1] in downloads:\n",
    "        cnf = conf['config_name']\n",
    "        conf_list.append(cnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_parquet_file_list(text:str):\n",
    "    pattern = r'download href=\"/datasets/wikimedia/wikipedia/resolve/main/.*\\.parquet\\?download=true\">\\d* MB'\n",
    "    substrings = re.findall(pattern, text)\n",
    "    return substrings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_one_parqet_file_per_conf(cnf):\n",
    "    base_url = 'https://huggingface.co/datasets/wikimedia/wikipedia/tree/main/'\n",
    "    url = base_url  + cnf\n",
    "    resp = requests.get(url)\n",
    "    text = resp.content.decode('utf-8')\n",
    "    parquet_files = get_parquet_file_list(text)\n",
    "    \n",
    "    urls_parquet = []\n",
    "    for f in parquet_files:\n",
    "        f = f.replace('download href=\"', '').replace(\"MB\", '')\n",
    "    \n",
    "        url_p = f.split('\">')[0]\n",
    "        size_p = f.split('\">')[-1]\n",
    "        urls_parquet.append([url_p.strip(), size_p.strip()])\n",
    "    \n",
    "    \n",
    "    urls_parquet = sorted(urls_parquet, key=lambda u: u[-1])\n",
    "\n",
    "    min_size = 150 # MB, try to get the small file, but greater than this if possible\n",
    "    if len(urls_parquet) ==1: \n",
    "        return urls_parquet[0]\n",
    "    else:\n",
    "        result = None\n",
    "        for u in urls_parquet:\n",
    "            result = u\n",
    "            if int(result[-1]) > min_size:\n",
    "                return result\n",
    "        return result\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['/datasets/wikimedia/wikipedia/resolve/main/20231101.ca/train-00001-of-00004.parquet?download=true',\n",
       "   '209'],\n",
       "  'ca'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.cs/train-00002-of-00004.parquet?download=true',\n",
       "   '195'],\n",
       "  'cs'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.da/train-00000-of-00002.parquet?download=true',\n",
       "   '203'],\n",
       "  'da'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.de/train-00014-of-00020.parquet?download=true',\n",
       "   '220'],\n",
       "  'de'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.en/train-00028-of-00041.parquet?download=true',\n",
       "   '188'],\n",
       "  'en'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.es/train-00010-of-00013.parquet?download=true',\n",
       "   '167'],\n",
       "  'es'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.fi/train-00002-of-00003.parquet?download=true',\n",
       "   '171'],\n",
       "  'fi'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.fr/train-00011-of-00017.parquet?download=true',\n",
       "   '169'],\n",
       "  'fr'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.hr/train-00000-of-00001.parquet?download=true',\n",
       "   '275'],\n",
       "  'hr'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.hu/train-00003-of-00004.parquet?download=true',\n",
       "   '216'],\n",
       "  'hu'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.it/train-00007-of-00010.parquet?download=true',\n",
       "   '218'],\n",
       "  'it'),\n",
       " (None, 'la'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.nl/train-00001-of-00006.parquet?download=true',\n",
       "   '304'],\n",
       "  'nl'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.no/train-00001-of-00003.parquet?download=true',\n",
       "   '175'],\n",
       "  'no'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.pl/train-00005-of-00006.parquet?download=true',\n",
       "   '231'],\n",
       "  'pl'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.pt/train-00002-of-00006.parquet?download=true',\n",
       "   '203'],\n",
       "  'pt'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.ro/train-00001-of-00002.parquet?download=true',\n",
       "   '195'],\n",
       "  'ro'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.sk/train-00000-of-00001.parquet?download=true',\n",
       "   '240'],\n",
       "  'sk'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.sl/train-00000-of-00001.parquet?download=true',\n",
       "   '267'],\n",
       "  'sl'),\n",
       " (['/datasets/wikimedia/wikipedia/resolve/main/20231101.sv/train-00004-of-00005.parquet?download=true',\n",
       "   '198'],\n",
       "  'sv')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parquet_file_paths = []\n",
    "for conf in conf_list:\n",
    "     parquet_file_paths.append((get_one_parqet_file_per_conf(conf), conf.split('.')[-1]))\n",
    "\n",
    "parquet_file_paths  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/parquet/ca.train-00001-of-00004.parquet is existing.\n",
      "../data/parquet/cs.train-00002-of-00004.parquet is existing.\n",
      "../data/parquet/da.train-00000-of-00002.parquet is existing.\n",
      "../data/parquet/de.train-00014-of-00020.parquet is existing.\n",
      "../data/parquet/en.train-00028-of-00041.parquet is existing.\n",
      "../data/parquet/es.train-00010-of-00013.parquet is existing.\n",
      "../data/parquet/fi.train-00002-of-00003.parquet is existing.\n",
      "../data/parquet/fr.train-00011-of-00017.parquet is existing.\n",
      "../data/parquet/hr.train-00000-of-00001.parquet is existing.\n",
      "../data/parquet/hu.train-00003-of-00004.parquet is existing.\n",
      "../data/parquet/it.train-00007-of-00010.parquet is existing.\n",
      "downloading /datasets/wikimedia/wikipedia/resolve/main/20231101.nl/train-00001-of-00006.parquet?download=true to ../data/parquet/nl.train-00001-of-00006.parquet\n",
      "downloading /datasets/wikimedia/wikipedia/resolve/main/20231101.no/train-00001-of-00003.parquet?download=true to ../data/parquet/no.train-00001-of-00003.parquet\n",
      "downloading /datasets/wikimedia/wikipedia/resolve/main/20231101.pl/train-00005-of-00006.parquet?download=true to ../data/parquet/pl.train-00005-of-00006.parquet\n",
      "downloading /datasets/wikimedia/wikipedia/resolve/main/20231101.pt/train-00002-of-00006.parquet?download=true to ../data/parquet/pt.train-00002-of-00006.parquet\n",
      "downloading /datasets/wikimedia/wikipedia/resolve/main/20231101.ro/train-00001-of-00002.parquet?download=true to ../data/parquet/ro.train-00001-of-00002.parquet\n",
      "downloading /datasets/wikimedia/wikipedia/resolve/main/20231101.sk/train-00000-of-00001.parquet?download=true to ../data/parquet/sk.train-00000-of-00001.parquet\n",
      "downloading /datasets/wikimedia/wikipedia/resolve/main/20231101.sl/train-00000-of-00001.parquet?download=true to ../data/parquet/sl.train-00000-of-00001.parquet\n",
      "downloading /datasets/wikimedia/wikipedia/resolve/main/20231101.sv/train-00004-of-00005.parquet?download=true to ../data/parquet/sv.train-00004-of-00005.parquet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def download_file(path, local_filename):\n",
    "    base_url = \"https://huggingface.co\"\n",
    "    url = base_url + path\n",
    "    response = requests.get(url, stream=True)\n",
    "    \n",
    "    with open(local_filename, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=128):\n",
    "            file.write(chunk)\n",
    "\n",
    "\n",
    "for pths in parquet_file_paths:\n",
    "    if pths[0] is None:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    file_path  = pths[0][0]\n",
    "    lang = pths[1]\n",
    "    \n",
    "    # print(file_path)\n",
    "    file_save_as = '../data/parquet/' + lang+\".\"+file_path.split('?')[0].split('/')[-1]\n",
    "    \n",
    "    # print(file_save_as)\n",
    "\n",
    "    if not os.path.exists(file_save_as):\n",
    "        print(f'downloading {file_path} to {file_save_as}')\n",
    "        download_file(file_path, file_save_as)\n",
    "    else: \n",
    "        print(f'{file_save_as} is existing.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_llm",
   "language": "python",
   "name": "train_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
